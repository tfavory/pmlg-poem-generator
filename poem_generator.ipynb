{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a model and generate poems\n",
    "\n",
    "This notebook has two objectives:\n",
    "    - load a trained poem generator\n",
    "    - load a trained rhyme generator\n",
    "    - Generate some poetry\n",
    "    \n",
    "\n",
    "## Importing packages and loading models\n",
    "We start by importing a couple of packages and load models previously trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  # version 1.9 or above\n",
    "tf.enable_eager_execution()  # Execution of code as it runs in the notebook. Normally, TensorFlow looks up the whole code before execution for efficiency.\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
    "import numpy as np\n",
    "import re\n",
    "from tensorflow.train import AdamOptimizer\n",
    "from tensorflow.losses import sparse_softmax_cross_entropy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models and hyperparameters\n",
    "\n",
    "Now we can load hyperparameters for both the poem generator and the rhyme generator\n",
    "\n",
    "Let's start with the poem generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load hyperparameters and layers' weights previously saved\n",
    "hyperparameters_poems = np.load('hyperparameters_poems.npy')[()]\n",
    "embedding_weights_poems = np.load('embedding_weights_poems.npy')\n",
    "gru_weights_poems = np.load('gru_weights_poems.npy')\n",
    "fc_weights_poems = np.load('fc_weights_poems.npy')\n",
    "char2idx_poems = np.load('char2idx_poems.npy')[()]\n",
    "idx2char_poems = np.load('idx2char_poems.npy')[()]\n",
    "\n",
    "# Hyperparameters\n",
    "max_length_poems = hyperparameters_poems['max_length']  # Maximum length sentence we want per input in the network\n",
    "embedding_dim_poems = hyperparameters_poems['embedding_dim']  # number of 'meaningful' features to learn. Ex: ['queen', 'king', 'man', 'woman'] has a least 2 embedding dimension: royalty and gender.\n",
    "units_poems = hyperparameters_poems['units']  # In keras: number of output of a sequence. In short it rem\n",
    "BATCH_SIZE_poems = hyperparameters_poems['BATCH_SIZE']\n",
    "BUFFER_SIZE_poems = hyperparameters_poems['BUFFER_SIZE']\n",
    "vocab_size_poems = len(dict(idx2char_poems))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the hyperparameters and weights for the rhyme generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load hyperparameters and layers' weights previously saved\n",
    "hyperparameters_rhymes = np.load('hyperparameters_rhymes.npy')[()]\n",
    "embedding_weights_rhymes = np.load('embedding_weights_rhymes.npy')\n",
    "gru_weights_rhymes = np.load('gru_weights_rhymes.npy')\n",
    "fc_weights_rhymes = np.load('fc_weights_rhymes.npy')\n",
    "char2idx_rhymes = np.load('word2idx_rhymes.npy')[()]\n",
    "idx2char_rhymes = np.load('idx2word_rhymes.npy')[()]\n",
    "\n",
    "# Hyperparameters\n",
    "max_length_rhymes = hyperparameters_rhymes['max_length']  # Maximum length sentence we want per input in the network\n",
    "embedding_dim_rhymes = hyperparameters_rhymes['embedding_dim']  # number of 'meaningful' features to learn. Ex: ['queen', 'king', 'man', 'woman'] has a least 2 embedding dimension: royalty and gender.\n",
    "units_rhymes = hyperparameters_rhymes['units']  # In keras: number of output of a sequence. In short it rem\n",
    "BATCH_SIZE_rhymes = hyperparameters_rhymes['BATCH_SIZE']\n",
    "BUFFER_SIZE_rhymes = hyperparameters_rhymes['BUFFER_SIZE']\n",
    "vocab_size_rhymes = len(dict(idx2char_rhymes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models creation\n",
    "\n",
    "We now reproduce models with the same structure as the ones previously trained. \n",
    "\n",
    "*Note: There is no need for declaring two classes (one for proems, the other for rhymes). Indeed, both poems and rhymes models are based on the same architecture.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, units, batch_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.units = units\n",
    "        self.batch_sz = batch_size\n",
    "        self.embedding = Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = GRU(self.units, return_sequences=True, return_state=True, recurrent_activation='sigmoid', recurrent_initializer='glorot_uniform')\n",
    "        self.fc = Dense(vocab_size)\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, states = self.gru(x, initial_state=hidden)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        x = self.fc(output)\n",
    "        return x, states\n",
    "\n",
    "    \n",
    "model_poems = Model(vocab_size_poems, embedding_dim_poems, units_poems, BATCH_SIZE_poems)\n",
    "model_rhymes = Model(vocab_size_rhymes, embedding_dim_rhymes, units_rhymes, BATCH_SIZE_rhymes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we now face a problem when we want to change a layer's weights\n",
    "\n",
    "Ideally, changing weights should fit in one line of code like:\n",
    "\n",
    "```\n",
    "model_poem.gru.set_weights(gru_weights)\n",
    "```\n",
    "But it throws an error. A dirty get around consists in retraining the model on a very small dataset\n",
    "\n",
    "## Getting around weight initialization issues\n",
    "\n",
    "*I am improving this part*\n",
    "\n",
    "We simply retrain the model on one epoch and a small sample. We have to do it for both the poem generator and the rhyme generator.\n",
    "\n",
    "First, the poem generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is merely a copy of poem_model\n",
    "path = 'corpus.txt'\n",
    "with open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "text = text[: 10 * BUFFER_SIZE_poems + 1]  # Not sure BUFFER_SIZE + 1 would always be enough\n",
    "\n",
    "text = re.sub('[^a-z\\n]', ' ', text)\n",
    "text = text[::-1]  # Put the text backwards\n",
    "\n",
    "input_text = []\n",
    "target_text = []\n",
    "\n",
    "for f in range(0, len(text) - max_length_poems, max_length_poems):\n",
    "    inps = text[f : f + max_length_poems]\n",
    "    targ = text[f + 1 : f + 1 + max_length_poems]\n",
    "    input_text.append([char2idx_poems[i] for i in inps])\n",
    "    target_text.append([char2idx_poems[t] for t in targ])\n",
    "    \n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_text, target_text)).shuffle(BUFFER_SIZE_poems)\n",
    "dataset = dataset.apply(tf.contrib.data.batch_and_drop_remainder(BATCH_SIZE_poems))\n",
    "\n",
    "\n",
    "optimizer = AdamOptimizer()\n",
    "\n",
    "def loss_function(real, preds):\n",
    "    return sparse_softmax_cross_entropy(labels=real, logits=preds)\n",
    "\n",
    "\n",
    "hidden = model_poems.reset_states()  # initializes the hidden state at the start of every epoch\n",
    "\n",
    "for (batch, (inp, target)) in enumerate(dataset):\n",
    "      with tf.GradientTape() as tape:\n",
    "          predictions, hidden = model_poems(inp, hidden)  # feeds the hidden state back into the model\n",
    "          target = tf.reshape(target, (-1, ))  # reshapes for the loss function\n",
    "          loss = loss_function(target, predictions)\n",
    "\n",
    "      grads = tape.gradient(loss, model_poems.variables)\n",
    "      optimizer.apply_gradients(zip(grads, model_poems.variables), global_step=tf.train.get_or_create_global_step())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we repeat the process with the rhyme generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['men', 'be', 'sea', 'refrain', 'day', 'say', 'born', 'star', 'war', 'morn', 'birth', 'mirth', 'tree', 'men', 'again', 'thee', 'earth', 'birth', 'now', 'low', 'fell', 'so', 'vain', 'well', 'tree', 'fell', 'leaves', 'me', 'above', 'melody', 'tree', 'low', 'evermore', 'woe', 'land', 'glee', 'night', 'sea', 'land', 'night', 'appeared', 'light', 'lonely', 'day', 'brightness', 'away', 'raiment', 'night', 'darkness', 'light']\n"
     ]
    }
   ],
   "source": [
    "# This is merely a copy of rhyme_model\n",
    "path = 'rhymes.txt'\n",
    "with open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "\n",
    "text = text[: 100 * BUFFER_SIZE_rhymes]  # 100 * BUFFER_SIZE_rhymes may not always be enough\n",
    "text = re.sub('[^a-z\\n]', ' ', text)\n",
    "text = text.split('\\n')\n",
    "print(text[:50])\n",
    "input_text = []\n",
    "target_text = []\n",
    "\n",
    "for f in range(0, len(text) - max_length_rhymes, max_length_rhymes):\n",
    "    inps = text[f : f + max_length_rhymes]\n",
    "    targ = text[f + 1 : f + 1 + max_length_rhymes]\n",
    "    input_text.append([char2idx_rhymes[i] for i in inps])\n",
    "    target_text.append([char2idx_rhymes[t] for t in targ])\n",
    "    \n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_text, target_text)).shuffle(BUFFER_SIZE_rhymes)\n",
    "dataset = dataset.apply(tf.contrib.data.batch_and_drop_remainder(BATCH_SIZE_rhymes))\n",
    "\n",
    "\n",
    "optimizer = AdamOptimizer()\n",
    "\n",
    "def loss_function(real, preds):\n",
    "    return sparse_softmax_cross_entropy(labels=real, logits=preds)\n",
    "    \n",
    "hidden = model_rhymes.reset_states()  # initializes the hidden state at the start of every epoch\n",
    "\n",
    "for (batch, (inp, target)) in enumerate(dataset):\n",
    "      with tf.GradientTape() as tape:\n",
    "          predictions, hidden = model_rhymes(inp, hidden)  # feeds the hidden state back into the model\n",
    "          target = tf.reshape(target, (-1, ))  # reshapes for the loss function\n",
    "          loss = loss_function(target, predictions)\n",
    "\n",
    "      grads = tape.gradient(loss, model_rhymes.variables)\n",
    "      optimizer.apply_gradients(zip(grads, model_rhymes.variables), global_step=tf.train.get_or_create_global_step())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading our weights back in the model\n",
    "\n",
    "We can finally plug the weights we have loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_poems.embedding.set_weights(np.asarray(embedding_weights_poems))\n",
    "model_poems.gru.set_weights(gru_weights_poems)\n",
    "model_poems.fc.set_weights(fc_weights_poems)\n",
    "\n",
    "model_rhymes.embedding.set_weights(np.asarray(embedding_weights_rhymes))\n",
    "model_rhymes.gru.set_weights(gru_weights_rhymes)\n",
    "model_rhymes.fc.set_weights(fc_weights_rhymes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation\n",
    "\n",
    "Finally, we can generate some poetry text from our model.\n",
    "\n",
    "First the rhymes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 0.4\n",
    "\n",
    "num_generate = 20  # number of characters to generate\n",
    "start_string = ['fell', 'vain', 'well', 'tree', 'fell', 'leave', 'me', 'above', 'melody']  # beginning of the generated text. TODO: try start_string = ' '\n",
    "input_eval = [char2idx_rhymes[s] for s in start_string]  # converts start_string to numbers the model understands\n",
    "input_eval = tf.expand_dims(input_eval, 0)  # \n",
    "\n",
    "text_generated = []\n",
    "\n",
    "\n",
    "hidden = [tf.zeros((1, units_rhymes))]\n",
    "for i in range(num_generate):\n",
    "    predictions, hidden = model_rhymes(input_eval, hidden)  # predictions holds the probabily for each character to be most adequate continuation\n",
    "   \n",
    "    predictions = predictions / temperature  # alters characters' probabilities to be picked (but keeps the order)\n",
    "    predicted_id = tf.multinomial(tf.exp(predictions), num_samples=1)[0][0].numpy()  # picks the next character for the generated text\n",
    "    input_eval = tf.expand_dims([predicted_id], 0)\n",
    "    text_generated += [idx2char_rhymes[predicted_id]]\n",
    "\n",
    "rhymes = text_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature = 0.5 \n",
      "\n",
      "Poem : \n",
      "\n",
      "\n",
      "then crossed the little fern and blooms her grandme\n",
      "in a golden hair andme\n",
      "and she answered   i have droundme\n",
      "there in silence andme\n",
      "and listened  and smiled  and she was cuddme\n",
      "the wind is in the shrandme\n",
      "that s the way for liberty  its pictures drandme\n",
      "he lived in the rose andme\n",
      "and the glory of gladness and its suddme\n",
      "for he loves the singled hair andme\n",
      "an  then he asked for andme\n",
      "it is a place in the silentless andme\n",
      "and say that they ever promessions andme\n",
      "it seemed to thinking in the andme\n",
      "and he was in the other in the golden hair andme\n",
      "crushed in silver grandme\n",
      "and rider fair andme\n",
      "and said   never every one  as she cuddme\n",
      "where the visions andme\n",
      "that which was the vision and gladme\n",
      "Temperature = 0.7 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation step(generating text using the model learned)\n",
    "\n",
    "\n",
    "for temperature in [0.5, 0.7, 0.9, 1.1, 1.5]:\n",
    "    print('Temperature = {} \\n'.format(temperature))\n",
    "    text_generated = ''\n",
    "    for rhyme in rhymes:\n",
    "    \n",
    "        num_generate = 150  # number of characters to generate\n",
    "        start_string = text_generated + rhyme[::-1]  # beginning of the generated text. TODO: try start_string = ' '\n",
    "        input_eval = [char2idx_poems[s] for s in start_string]  # converts start_string to numbers the model understands\n",
    "        input_eval = tf.expand_dims(input_eval, 0)  # \n",
    "        hidden = [tf.zeros((1, units_poems))]\n",
    "        \n",
    "        b = True\n",
    "        c = 1\n",
    "        addition = ' '\n",
    "        tmp = start_string + ' '\n",
    "        while b == True:\n",
    "            predictions, hidden = model_poems(input_eval, hidden)  # predictions holds the probabily for each character to be most adequate continuation\n",
    "           \n",
    "            predictions = predictions / temperature  # alters characters' probabilities to be picked (but keeps the order)\n",
    "            predicted_id = tf.multinomial(tf.exp(predictions), num_samples=1)[0][0].numpy()  # picks the next character for the generated text\n",
    "            input_eval = tf.expand_dims([predicted_id], 0)\n",
    "            tmp += idx2char_poems[predicted_id]\n",
    "            addition += idx2char_poems[predicted_id]\n",
    "            c += 1\n",
    "            if idx2char_poems[predicted_id] == '\\n' or c > num_generate:\n",
    "                text_generated += rhyme[::-1] + addition\n",
    "                b = False\n",
    "    print('Poem : \\n')\n",
    "    print (text_generated[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
