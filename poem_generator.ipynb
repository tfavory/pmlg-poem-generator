{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a model and generate poems\n",
    "\n",
    "This notebook has two objectives:\n",
    "    - load a trained poem generator\n",
    "    - load a trained rhyme generator\n",
    "    - Generate some poetry\n",
    "    \n",
    "\n",
    "## Importing packages and loading models\n",
    "We start by importing a couple of packages and load models previously trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf  # version 1.9 or above\n",
    "tf.enable_eager_execution()  # Execution of code as it runs in the notebook. Normally, TensorFlow looks up the whole code before execution for efficiency.\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
    "import numpy as np\n",
    "import re\n",
    "from tensorflow.train import AdamOptimizer\n",
    "from tensorflow.losses import sparse_softmax_cross_entropy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models and hyperparameters\n",
    "\n",
    "Now we can load hyperparameters for both the poem generator and the rhyme generator\n",
    "\n",
    "Let's start with the poem generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load hyperparameters and layers' weights previously saved\n",
    "hyperparameters_poems = np.load('hyperparameters_poems.npy')[()]\n",
    "embedding_weights_poems = np.load('embedding_weights_poems.npy')\n",
    "gru_weights_poems = np.load('gru_weights_poems.npy')\n",
    "fc_weights_poems = np.load('fc_weights_poems.npy')\n",
    "char2idx_poems = np.load('char2idx_poems.npy')[()]\n",
    "idx2char_poems = np.load('idx2char_poems.npy')[()]\n",
    "\n",
    "# Hyperparameters\n",
    "max_length_poems = hyperparameters_poems['max_length']  # Maximum length sentence we want per input in the network\n",
    "embedding_dim_poems = hyperparameters_poems['embedding_dim']  # number of 'meaningful' features to learn. Ex: ['queen', 'king', 'man', 'woman'] has a least 2 embedding dimension: royalty and gender.\n",
    "units_poems = hyperparameters_poems['units']  # In keras: number of output of a sequence. In short it rem\n",
    "BATCH_SIZE_poems = hyperparameters_poems['BATCH_SIZE']\n",
    "BUFFER_SIZE_poems = hyperparameters_poems['BUFFER_SIZE']\n",
    "vocab_size_poems = len(dict(idx2char_poems))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the hyperparameters and weights for the rhyme generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load hyperparameters and layers' weights previously saved\n",
    "hyperparameters_rhymes = np.load('hyperparameters_rhymes.npy')[()]\n",
    "embedding_weights_rhymes = np.load('embedding_weights_rhymes.npy')\n",
    "gru_weights_rhymes = np.load('gru_weights_rhymes.npy')\n",
    "fc_weights_rhymes = np.load('fc_weights_rhymes.npy')\n",
    "char2idx_rhymes = np.load('word2idx_rhymes.npy')[()]\n",
    "idx2char_rhymes = np.load('idx2word_rhymes.npy')[()]\n",
    "\n",
    "# Hyperparameters\n",
    "max_length_rhymes = hyperparameters_rhymes['max_length']  # Maximum length sentence we want per input in the network\n",
    "embedding_dim_rhymes = hyperparameters_rhymes['embedding_dim']  # number of 'meaningful' features to learn. Ex: ['queen', 'king', 'man', 'woman'] has a least 2 embedding dimension: royalty and gender.\n",
    "units_rhymes = hyperparameters_rhymes['units']  # In keras: number of output of a sequence. In short it rem\n",
    "BATCH_SIZE_rhymes = hyperparameters_rhymes['BATCH_SIZE']\n",
    "BUFFER_SIZE_rhymes = hyperparameters_rhymes['BUFFER_SIZE']\n",
    "vocab_size_rhymes = len(dict(idx2char_rhymes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models creation\n",
    "\n",
    "We now reproduce models with the same structure as the ones previously trained. \n",
    "\n",
    "*Note: There is no need for declaring two classes (one for proems, the other for rhymes). Indeed, both poems and rhymes models are based on the same architecture.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Model(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, units, batch_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.units = units\n",
    "        self.batch_sz = batch_size\n",
    "        self.embedding = Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = GRU(self.units, return_sequences=True, return_state=True, recurrent_activation='sigmoid', recurrent_initializer='glorot_uniform')\n",
    "        self.fc = Dense(vocab_size)\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, states = self.gru(x, initial_state=hidden)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        x = self.fc(output)\n",
    "        return x, states\n",
    "\n",
    "    \n",
    "model_poems = Model(vocab_size_poems, embedding_dim_poems, units_poems, BATCH_SIZE_poems)\n",
    "model_rhymes = Model(vocab_size_rhymes, embedding_dim_rhymes, units_rhymes, BATCH_SIZE_rhymes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we now face a problem when we want to change a layer's weights\n",
    "\n",
    "Ideally, changing weights should fit in one line of code like:\n",
    "\n",
    "```\n",
    "model_poem.gru.set_weights(gru_weights)\n",
    "```\n",
    "But it throws an error. A dirty get around consists in retraining the model on a very small dataset\n",
    "\n",
    "## Getting around weight initialization issues\n",
    "\n",
    "*I am improving this part*\n",
    "\n",
    "We simply retrain the model on one epoch and a small sample. We have to do it for both the poem generator and the rhyme generator.\n",
    "\n",
    "First, the poem generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-4b671a670bac>:20: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n"
     ]
    }
   ],
   "source": [
    "# This is merely a copy of poem_model\n",
    "path = 'corpus.txt'\n",
    "with open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "text = text[: 10 * BUFFER_SIZE_poems + 1]  # Not sure BUFFER_SIZE + 1 would always be enough\n",
    "\n",
    "text = re.sub('[^a-z\\n]', ' ', text)\n",
    "text = text[::-1]  # Put the text backwards\n",
    "\n",
    "input_text = []\n",
    "target_text = []\n",
    "\n",
    "for f in range(0, len(text) - max_length_poems, max_length_poems):\n",
    "    inps = text[f : f + max_length_poems]\n",
    "    targ = text[f + 1 : f + 1 + max_length_poems]\n",
    "    input_text.append([char2idx_poems[i] for i in inps])\n",
    "    target_text.append([char2idx_poems[t] for t in targ])\n",
    "    \n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_text, target_text)).shuffle(BUFFER_SIZE_poems)\n",
    "dataset = dataset.apply(tf.contrib.data.batch_and_drop_remainder(BATCH_SIZE_poems))\n",
    "\n",
    "\n",
    "optimizer = AdamOptimizer()\n",
    "\n",
    "def loss_function(real, preds):\n",
    "    return sparse_softmax_cross_entropy(labels=real, logits=preds)\n",
    "\n",
    "\n",
    "hidden = model_poems.reset_states()  # initializes the hidden state at the start of every epoch\n",
    "\n",
    "for (batch, (inp, target)) in enumerate(dataset):\n",
    "      with tf.GradientTape() as tape:\n",
    "          predictions, hidden = model_poems(inp, hidden)  # feeds the hidden state back into the model\n",
    "          target = tf.reshape(target, (-1, ))  # reshapes for the loss function\n",
    "          loss = loss_function(target, predictions)\n",
    "\n",
    "      grads = tape.gradient(loss, model_poems.variables)\n",
    "      optimizer.apply_gradients(zip(grads, model_poems.variables), global_step=tf.train.get_or_create_global_step())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we repeat the process with the rhyme generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is merely a copy of rhyme_model\n",
    "path = 'rhymes.txt'\n",
    "with open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "\n",
    "text = text[: 100 * BUFFER_SIZE_rhymes]  # 100 * BUFFER_SIZE_rhymes may not always be enough\n",
    "text = re.sub('[^a-z\\n]', ' ', text)\n",
    "text = text.split('\\n')\n",
    "input_text = []\n",
    "target_text = []\n",
    "\n",
    "for f in range(0, len(text) - max_length_rhymes, max_length_rhymes):\n",
    "    inps = text[f : f + max_length_rhymes]\n",
    "    targ = text[f + 1 : f + 1 + max_length_rhymes]\n",
    "    input_text.append([char2idx_rhymes[i] for i in inps])\n",
    "    target_text.append([char2idx_rhymes[t] for t in targ])\n",
    "    \n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_text, target_text)).shuffle(BUFFER_SIZE_rhymes)\n",
    "dataset = dataset.apply(tf.contrib.data.batch_and_drop_remainder(BATCH_SIZE_rhymes))\n",
    "\n",
    "\n",
    "optimizer = AdamOptimizer()\n",
    "\n",
    "def loss_function(real, preds):\n",
    "    return sparse_softmax_cross_entropy(labels=real, logits=preds)\n",
    "    \n",
    "hidden = model_rhymes.reset_states()  # initializes the hidden state at the start of every epoch\n",
    "\n",
    "for (batch, (inp, target)) in enumerate(dataset):\n",
    "      with tf.GradientTape() as tape:\n",
    "          predictions, hidden = model_rhymes(inp, hidden)  # feeds the hidden state back into the model\n",
    "          target = tf.reshape(target, (-1, ))  # reshapes for the loss function\n",
    "          loss = loss_function(target, predictions)\n",
    "\n",
    "      grads = tape.gradient(loss, model_rhymes.variables)\n",
    "      optimizer.apply_gradients(zip(grads, model_rhymes.variables), global_step=tf.train.get_or_create_global_step())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading our weights back in the model\n",
    "\n",
    "We can finally plug the weights we have loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_poems.embedding.set_weights(np.asarray(embedding_weights_poems))\n",
    "model_poems.gru.set_weights(gru_weights_poems)\n",
    "model_poems.fc.set_weights(fc_weights_poems)\n",
    "\n",
    "model_rhymes.embedding.set_weights(np.asarray(embedding_weights_rhymes))\n",
    "model_rhymes.gru.set_weights(gru_weights_rhymes)\n",
    "model_rhymes.fc.set_weights(fc_weights_rhymes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation\n",
    "\n",
    "Finally, we can generate some poetry text from our model.\n",
    "\n",
    "First the rhymes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temperature = 0.4\n",
    "\n",
    "num_generate = 20  # number of characters to generate\n",
    "start_string = ['fell', 'vain', 'well', 'tree', 'fell', 'leave', 'me', 'above', 'melody']  # beginning of the generated text. TODO: try start_string = ' '\n",
    "input_eval = [char2idx_rhymes[s] for s in start_string]  # converts start_string to numbers the model understands\n",
    "input_eval = tf.expand_dims(input_eval, 0)  # \n",
    "\n",
    "text_generated = []\n",
    "\n",
    "\n",
    "hidden = [tf.zeros((1, units_rhymes))]\n",
    "for i in range(num_generate):\n",
    "    predictions, hidden = model_rhymes(input_eval, hidden)  # predictions holds the probabily for each character to be most adequate continuation\n",
    "   \n",
    "    predictions = predictions / temperature  # alters characters' probabilities to be picked (but keeps the order)\n",
    "    predicted_id = tf.multinomial(tf.exp(predictions), num_samples=1)[0][0].numpy()  # picks the next character for the generated text\n",
    "    input_eval = tf.expand_dims([predicted_id], 0)\n",
    "    text_generated += [idx2char_rhymes[predicted_id]]\n",
    "\n",
    "rhymes = text_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature = 0.5 \n",
      "\n",
      "Poem : \n",
      "\n",
      "\n",
      "in silence  he repeated to her  and twenty miles\n",
      "and then there stood at tiles\n",
      "and the flower that had been painted with wonder  and there we roam\n",
      "but we were terrible to other home\n",
      "touched to their dwelling  here\n",
      "and ghastly as a place in the bridge of things on the fight\n",
      "for falls before the tears that night\n",
      "he looked in those abins in people s eyes\n",
      "and the earth are the piles and flowers would think\n",
      "they sailed  the firected story  as he gave me another drink\n",
      "to casey s sister spoiled the honest glories broke\n",
      "and see him root and clear and near\n",
      "bear noon flew in a moment  and my flutters have   as he sighed\n",
      "when the strong lines of the conscience and slow and full many a name\n",
      "the world is love  not a loving kline\n",
      "christmas things to make the most of the line\n",
      "there  when seas alive  in such numbers had watched on the flood\n",
      "he knew                                                                                                           was it shattered  then   never  so swiftly grew\n",
      "too soon that comes to the land and blood\n",
      "\n",
      "\n",
      "Temperature = 0.7 \n",
      "\n",
      "Poem : \n",
      "\n",
      "\n",
      "i made my duty  it is only as a man has touched its class as things  who pass with their dear rosy miles\n",
      "when the heated was it tiles\n",
      "you can find me with love around me ever roam\n",
      "then the centuries of the yellow home\n",
      "and twinkle on her cottage   here\n",
      "with the men in his crape in the fight\n",
      "when the blessings of the night\n",
      "in the hells of his eyes\n",
      "they are nearing the victories might used to think\n",
      "and may be in the rest he might drink\n",
      "when they thundered and broke\n",
      "and hinking littles  and once again  far and near\n",
      "and i loved it  as man  he must be sighed\n",
      "thank god  that was the night or telling his name\n",
      "the battles  she  was there on her kline\n",
      "out where they seemed to glittering line\n",
      "and  in such numbers had watched on the flood\n",
      "he knew                                                                                                           was it shattered  then   never  so swiftly grew\n",
      "too soon that comes to the land and blood\n",
      "\n",
      "\n",
      "Temperature = 0.9 \n",
      "\n",
      "Poem : \n",
      "\n",
      "\n",
      "and in france was danced  and the pretty miles\n",
      "no winds and rings and tiles\n",
      "o er the dolished  and a moment gave to roam\n",
      "we looking to his people  there s no place like home\n",
      "that makes all are  he has singing  here\n",
      "and all things on the fight\n",
      "and when he smiled and stilly night\n",
      "and he reached their wondering eyes\n",
      "this is the way that the deed that she would think\n",
      "nor make another drink\n",
      "and when the lady s read  but it broke\n",
      "it touched her answered near\n",
      "till the letters of france  it was a stone   he sighed\n",
      "she said   not  oh  heaven had takes his name\n",
      "and freely kline\n",
      "and the lover and the line\n",
      "then on the shingle  who had watched on the flood\n",
      "he knew                                                                                                           was it shattered  then   never  so swiftly grew\n",
      "too soon that comes to the land and blood\n",
      "\n",
      "\n",
      "Temperature = 1.1 \n",
      "\n",
      "Poem : \n",
      "\n",
      "\n",
      "and listened and looked twenty miles\n",
      "and i thought of all my heart is filled with tiles\n",
      "i didn t led on the line  as i roam\n",
      "the years are three slowly home\n",
      "glittering  singing  here\n",
      "and bust o  ho  across the way to learn to fight\n",
      "he told me uttered  i was crowned to night\n",
      "the walls are shattered all over the child s eyes\n",
      "the  dear blue eyes  especially   let me  do you give it  it didn t want to think\n",
      "and in their souls are shattered o er what they might drink\n",
      "in the hands that never  when the lances should never broke\n",
      "and wondered  what is passing far and near\n",
      "they sailed  they sailed a thing  and he sighed\n",
      "he was ringing over hands they called his name\n",
      "his sweet ministers never kline\n",
      "but it was sure in the line\n",
      "that ever in my heart and flood\n",
      "the boy stood on the  i never knew\n",
      "it looked for the horses  the wind is grew\n",
      "and the man that comes to the land and blood\n",
      "\n",
      "\n",
      "Temperature = 1.5 \n",
      "\n",
      "Poem : \n",
      "\n",
      "\n",
      "and oft the islands of right  and twenty miles\n",
      "he losses of its golden tiles\n",
      "and fields and bloody shoes are to roam\n",
      "across the waters hollow home\n",
      "and the golden tresses that lizs the thing  here\n",
      "and i leaned  and have sailed his head on the fight\n",
      "and listened and stumbled by night\n",
      "and he looked on his look of rats before the battery s eyes\n",
      "and the means that we might used to think\n",
      "the thunder stracs the rest he might drink\n",
      "and when he watched the fence  and that leaped and broke\n",
      "a moment on the hill smile  o er herv  come down in the day she is near\n",
      "and that the well was billy   as he sighed\n",
      "let us be guidance  it is a place in the large of a name\n",
      "the fights of wasting kline\n",
      "and the coming lines of the empress the matter  richest hold on the line\n",
      "and in a woman s sparkling flood\n",
      "and he was die  he never knew\n",
      "and then he smiled on his nose up grew\n",
      "the thunder steeds  and strength and blood\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation step(generating text using the model learned)\n",
    "\n",
    "\n",
    "for temperature in [0.5, 0.7, 0.9, 1.1, 1.5]:\n",
    "    print('Temperature = {} \\n'.format(temperature))\n",
    "    text_generated = ''\n",
    "    for rhyme in rhymes:\n",
    "    \n",
    "        num_generate = 150  # number of characters to generate\n",
    "        start_string = text_generated + rhyme[::-1]  # beginning of the generated text. TODO: try start_string = ' '\n",
    "        input_eval = [char2idx_poems[s] for s in start_string]  # converts start_string to numbers the model understands\n",
    "        input_eval = tf.expand_dims(input_eval, 0)  # \n",
    "        hidden = [tf.zeros((1, units_poems))]\n",
    "        \n",
    "        b = True\n",
    "        c = 1\n",
    "        added_text = ''\n",
    "        while b == True:\n",
    "            predictions, hidden = model_poems(input_eval, hidden)  # predictions holds the probabily for each character to be most adequate continuation\n",
    "           \n",
    "            predictions = predictions / temperature  # alters characters' probabilities to be picked (but keeps the order)\n",
    "            predicted_id = tf.multinomial(tf.exp(predictions), num_samples=1)[0][0].numpy()  # picks the next character for the generated text\n",
    "            input_eval = tf.expand_dims([predicted_id], 0)\n",
    "            added_text += idx2char_poems[predicted_id]\n",
    "            c += 1\n",
    "            if idx2char_poems[predicted_id] == '\\n' or c > num_generate:\n",
    "                text_generated += rhyme[::-1] + added_text\n",
    "                b = False\n",
    "    print('Poem : \\n')\n",
    "    print (text_generated[::-1])\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
