{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a model and generate poems\n",
    "\n",
    "This notebook has two objectives:\n",
    "    - load a trained poem generator\n",
    "    - load a trained rhyme generator\n",
    "    - Generate some poetry\n",
    "    \n",
    "\n",
    "## Importing packages and loading models\n",
    "We start by importing a couple of packages and load models previously trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf  # version 1.9 or above\n",
    "tf.enable_eager_execution()  # Execution of code as it runs in the notebook. Normally, TensorFlow looks up the whole code before execution for efficiency.\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
    "import numpy as np\n",
    "import re\n",
    "from tensorflow.train import AdamOptimizer\n",
    "from tensorflow.losses import sparse_softmax_cross_entropy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models and hyperparameters\n",
    "\n",
    "Now we can load hyperparameters for both the poem generator and the rhyme generator\n",
    "\n",
    "Let's start with the poem generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load hyperparameters and layers' weights previously saved\n",
    "parameters_poems = np.load('model_poems.npy')[()]\n",
    "# get the pretrained weights\n",
    "embedding_weights_poems = parameters_poems['embedding_weights']\n",
    "gru_weights_poems = parameters_poems['gru_weights']\n",
    "fc_weights_poems = parameters_poems['fc_weights']\n",
    "\n",
    "# dictionaries character to integer / integer to character\n",
    "char2idx_poems = parameters_poems['char2idx']\n",
    "idx2char_poems = parameters_poems['idx2char']\n",
    "\n",
    "# Hyperparameters\n",
    "max_length_poems = parameters_poems['max_length']  # Maximum length sentence we want per input in the network\n",
    "embedding_dim_poems = parameters_poems['embedding_dim']  # number of 'meaningful' features to learn. Ex: ['queen', 'king', 'man', 'woman'] has a least 2 embedding dimension: royalty and gender.\n",
    "units_poems = parameters_poems['units']  # In keras: number of output of a sequence. In short it rem\n",
    "BATCH_SIZE_poems = parameters_poems['BATCH_SIZE']\n",
    "BUFFER_SIZE_poems = parameters_poems['BUFFER_SIZE']\n",
    "\n",
    "vocab_size_poems = len(dict(idx2char_poems))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the hyperparameters and weights for the rhyme generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load hyperparameters and layers' weights previously saved\n",
    "parameters_rhymes = np.load('model_rhymes.npy')[()]\n",
    "# get the pretrained weights\n",
    "embedding_weights_rhymes = parameters_rhymes['embedding_weights']\n",
    "gru_weights_rhymes = parameters_rhymes['gru_weights']\n",
    "fc_weights_rhymes = parameters_rhymes['fc_weights']\n",
    "\n",
    "# dictionaries character to integer / integer to character\n",
    "word2idx_rhymes = parameters_rhymes['word2idx']\n",
    "idx2word_rhymes = parameters_rhymes['idx2word']\n",
    "\n",
    "# Hyperparameters\n",
    "max_length_rhymes = parameters_rhymes['max_length']  # Maximum length sentence we want per input in the network\n",
    "embedding_dim_rhymes = parameters_rhymes['embedding_dim']  # number of 'meaningful' features to learn. Ex: ['queen', 'king', 'man', 'woman'] has a least 2 embedding dimension: royalty and gender.\n",
    "units_rhymes = parameters_rhymes['units']  # In keras: number of output of a sequence. In short it rem\n",
    "BATCH_SIZE_rhymes = parameters_rhymes['BATCH_SIZE']\n",
    "BUFFER_SIZE_rhymes = parameters_rhymes['BUFFER_SIZE']\n",
    "\n",
    "vocab_size_rhymes = len(dict(idx2word_rhymes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models creation\n",
    "\n",
    "We now reproduce models with the same structure as the ones previously trained. \n",
    "\n",
    "*Note: There is no need for declaring two classes (one for proems, the other for rhymes). Indeed, both poems and rhymes models are based on the same architecture.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Model(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, units, batch_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.units = units\n",
    "        self.batch_sz = batch_size\n",
    "        self.embedding = Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = GRU(self.units, return_sequences=True, return_state=True, recurrent_activation='sigmoid', recurrent_initializer='glorot_uniform')\n",
    "        self.fc = Dense(vocab_size)\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, states = self.gru(x, initial_state=hidden)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        x = self.fc(output)\n",
    "        return x, states\n",
    "\n",
    "    \n",
    "model_poems = Model(vocab_size_poems, embedding_dim_poems, units_poems, BATCH_SIZE_poems)\n",
    "model_rhymes = Model(vocab_size_rhymes, embedding_dim_rhymes, units_rhymes, BATCH_SIZE_rhymes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting pretrained weights\n",
    "\n",
    "Let's plug our pretrained weights in our poem generator.\n",
    "We need to predict a blank character (I ignore the reason) before we may set the weights we've trained "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_generate = 1\n",
    "start_string = 'child'[::-1]\n",
    "input_eval = [char2idx_poems[s] for s in start_string]\n",
    "input_eval = tf.expand_dims(input_eval, 0)\n",
    "hidden = [tf.zeros((1, units_poems))]\n",
    "predictions, hidden = model_poems(input_eval, hidden)\n",
    "\n",
    "model_poems.embedding.set_weights(np.asarray(embedding_weights_poems))\n",
    "model_poems.gru.set_weights(gru_weights_poems)\n",
    "model_poems.fc.set_weights(fc_weights_poems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat the process with the rhyme generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_generate = 1  # number of characters to generate\n",
    "start_string = ['fell']  # beginning of the generated text. TODO: try start_string = ' '\n",
    "input_eval = [word2idx_rhymes[s] for s in start_string]  # converts start_string to numbers the model understands\n",
    "input_eval = tf.expand_dims(input_eval, 0)\n",
    "hidden = [tf.zeros((1, units_rhymes))]\n",
    "predictions, hidden = model_rhymes(input_eval, hidden)\n",
    "\n",
    "model_rhymes.embedding.set_weights(np.asarray(embedding_weights_rhymes))\n",
    "model_rhymes.gru.set_weights(gru_weights_rhymes)\n",
    "model_rhymes.fc.set_weights(fc_weights_rhymes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation\n",
    "\n",
    "Finally, we can generate some poetry text from our model.\n",
    "\n",
    "First the rhymes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temperature = 0.4\n",
    "\n",
    "num_generate = 4  # number of characters to generate\n",
    "start_string = ['fell', 'vain', 'well', 'tree', 'fell', 'leave', 'me', 'above', 'melody']  # beginning of the generated text. TODO: try start_string = ' '\n",
    "input_eval = [word2idx_rhymes[s] for s in start_string]  # converts start_string to numbers the model understands\n",
    "input_eval = tf.expand_dims(input_eval, 0) \n",
    "\n",
    "text_generated = []\n",
    "\n",
    "\n",
    "hidden = [tf.zeros((1, units_rhymes))]\n",
    "for i in range(num_generate):\n",
    "    predictions, hidden = model_rhymes(input_eval, hidden)  # predictions holds the probabily for each character to be most adequate continuation\n",
    "   \n",
    "    predictions = predictions / temperature  # alters characters' probabilities to be picked (but keeps the order)\n",
    "    predicted_id = tf.multinomial(tf.exp(predictions), num_samples=1)[0][0].numpy()  # picks the next character for the generated text\n",
    "    input_eval = tf.expand_dims([predicted_id], 0)\n",
    "    text_generated += [idx2word_rhymes[predicted_id]]\n",
    "\n",
    "rhymes = text_generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's generate some poetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature = 0.5 \n",
      "\n",
      "Poem : \n",
      "\n",
      "\n",
      "there  when seas alive  in such numbers had watched on the flood\n",
      "he knew                                                                                                           was it shattered  then   never  so swiftly grew\n",
      "too soon that comes to the land and blood\n",
      "\n",
      "\n",
      "Temperature = 0.7 \n",
      "\n",
      "Poem : \n",
      "\n",
      "\n",
      "there  when seas alive  in such numbers had watched on the flood\n",
      "he knew                                                                                                           was it shattered  then   never  so swiftly grew\n",
      "too soon that comes to the land and blood\n",
      "\n",
      "\n",
      "Temperature = 0.9 \n",
      "\n",
      "Poem : \n",
      "\n",
      "\n",
      "as for god s eyes are heaped and flood\n",
      "i live in my mother  for he never knew\n",
      "and then he smiled on his nose up grew\n",
      "the thunder steeds  and strength and blood\n",
      "\n",
      "\n",
      "Temperature = 1.1 \n",
      "\n",
      "Poem : \n",
      "\n",
      "\n",
      "this is the same as on the flood\n",
      "so she looked down by her brother knew\n",
      "and said   no  never  so swiftly grew\n",
      "too soon that comes to the land and blood\n",
      "\n",
      "\n",
      "Temperature = 1.5 \n",
      "\n",
      "Poem : \n",
      "\n",
      "\n",
      "they sailed above the flaming flood\n",
      "his faithful rock behind this knew\n",
      "and many rulers flowing anxious here and there grew\n",
      "the daily possession that comes to the land and blood\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation step(generating text using the model learned)\n",
    "\n",
    "\n",
    "for temperature in [0.5, 0.7, 0.9, 1.1, 1.5]:\n",
    "    print('Temperature = {} \\n'.format(temperature))\n",
    "    text_generated = ''\n",
    "    for rhyme in rhymes:\n",
    "    \n",
    "        num_generate = 150  # number of characters to generate\n",
    "        start_string = text_generated + rhyme[::-1]  # beginning of the generated text. TODO: try start_string = ' '\n",
    "        input_eval = [char2idx_poems[s] for s in start_string]  # converts start_string to numbers the model understands\n",
    "        input_eval = tf.expand_dims(input_eval, 0)  # \n",
    "        hidden = [tf.zeros((1, units_poems))]\n",
    "        \n",
    "        b = True\n",
    "        c = 1\n",
    "        added_text = ''\n",
    "        while b == True:\n",
    "            predictions, hidden = model_poems(input_eval, hidden)  # predictions holds the probabily for each character to be most adequate continuation\n",
    "           \n",
    "            predictions = predictions / temperature  # alters characters' probabilities to be picked (but keeps the order)\n",
    "            predicted_id = tf.multinomial(tf.exp(predictions), num_samples=1)[0][0].numpy()  # picks the next character for the generated text\n",
    "            input_eval = tf.expand_dims([predicted_id], 0)\n",
    "            added_text += idx2char_poems[predicted_id]\n",
    "            c += 1\n",
    "            if idx2char_poems[predicted_id] == '\\n' or c > num_generate:\n",
    "                text_generated += rhyme[::-1] + added_text\n",
    "                b = False\n",
    "    print('Poem : \\n')\n",
    "    print (text_generated[::-1])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
